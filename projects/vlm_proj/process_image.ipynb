{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a3bf72",
   "metadata": {},
   "source": [
    "## Core code of the image processing function\n",
    "\n",
    "This code module provides a series of image processing algorithms, including Sobel edge detection, Canny edge detection, Marr-Hildreth edge detection, Hough Transform, Active Contour (Snakes), and Thresholding-based Region Growing segmentation. Users can call different algorithms as needed and pass the corresponding parameters when calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb78425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageDraw\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage.filters import gaussian\n",
    "import os\n",
    "\n",
    "def sobel_detector(input_image, ksize=3):\n",
    "    # Convert to grayscale\n",
    "    gray_image = ImageOps.grayscale(input_image)\n",
    "    \n",
    "    image_array = np.array(gray_image)\n",
    "    \n",
    "    # Apply Sobel filter\n",
    "    sobel_x = cv2.Sobel(image_array, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    sobel_y = cv2.Sobel(image_array, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    \n",
    "    # Calculate magnitude of the gradient\n",
    "    magnitude = np.hypot(sobel_x, sobel_y)\n",
    "    magnitude = (magnitude / magnitude.max()) * 255\n",
    "    magnitude = magnitude.astype(np.uint8)\n",
    "    \n",
    "    # Convert back to PIL image\n",
    "    return Image.fromarray(magnitude)\n",
    "\n",
    "def canny_detector(input_image, low_threshold=50, high_threshold=150):\n",
    "\n",
    "    # Convert to grayscale\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    \n",
    "    # Apply Canny edge detector\n",
    "    edges = cv2.Canny(image_array, low_threshold, high_threshold)\n",
    "    \n",
    "    # Convert back to PIL image\n",
    "    return Image.fromarray(edges)\n",
    "\n",
    "def marr_hildreth_detector(input_image, sigma=3):\n",
    "\n",
    "    # Convert to grayscale\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred_image = cv2.GaussianBlur(image_array, (0, 0), sigma)\n",
    "    \n",
    "    # Apply Laplacian filter\n",
    "    laplacian = cv2.Laplacian(blurred_image, cv2.CV_64F)\n",
    "    \n",
    "    # Find zero crossings\n",
    "    zero_crossings = np.zeros_like(laplacian)\n",
    "    for i in range(1, laplacian.shape[0] - 1):\n",
    "        for j in range(1, laplacian.shape[1] - 1):\n",
    "            if laplacian[i, j] == 0:\n",
    "                if (laplacian[i+1, j] < 0 and laplacian[i-1, j] > 0) or (laplacian[i+1, j] > 0 and laplacian[i-1, j] < 0) or \\\n",
    "                   (laplacian[i, j+1] < 0 and laplacian[i, j-1] > 0) or (laplacian[i, j+1] > 0 and laplacian[i, j-1] < 0):\n",
    "                    zero_crossings[i, j] = 255\n",
    "            elif laplacian[i, j] < 0:\n",
    "                if (laplacian[i+1, j] > 0 or laplacian[i-1, j] > 0 or laplacian[i, j+1] > 0 or laplacian[i, j-1] > 0):\n",
    "                    zero_crossings[i, j] = 255\n",
    "            elif laplacian[i, j] > 0:\n",
    "                if (laplacian[i+1, j] < 0 or laplacian[i-1, j] < 0 or laplacian[i, j+1] < 0 or laplacian[i, j-1] < 0):\n",
    "                    zero_crossings[i, j] = 255\n",
    "\n",
    "    # Convert back to PIL image\n",
    "    zero_crossings = zero_crossings.astype(np.uint8)\n",
    "    return Image.fromarray(zero_crossings)\n",
    "\n",
    "def hough_transform(input_image, canny_low_threshold=50, canny_high_threshold=150, hough_threshold=100, max_lines=50):\n",
    "\n",
    "    # Convert to grayscale\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    \n",
    "    # Apply Canny edge detector\n",
    "    edges = cv2.Canny(image_array, canny_low_threshold, canny_high_threshold)\n",
    "    \n",
    "    # Apply Hough Line Transform\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, hough_threshold)\n",
    "    \n",
    "    # Draw lines on the original image\n",
    "    output_image = input_image.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(output_image)\n",
    "    if lines is not None:\n",
    "        for i, line in enumerate(lines[:max_lines]):  # Limit the number of lines drawn\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            draw.line((x1, y1, x2, y2), fill=(255, 0, 0), width=2)\n",
    "    return output_image\n",
    "def active_contour_tracing(input_image, init_points, alpha=0.5, beta=0.001, gamma=0.005, sigma=40.0):\n",
    "\n",
    "    # Convert to grayscale and apply Gaussian smoothing\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    image_array = gaussian(image_array, sigma=1.0)\n",
    "    \n",
    "    # Apply active contour (snake) algorithm\n",
    "    snake = active_contour(image_array, init_points, alpha=alpha, beta=beta, gamma=gamma)\n",
    "    \n",
    "    # Draw the snake contour on the original image\n",
    "    output_image = input_image.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(output_image)\n",
    "    for i in range(len(snake) - 1):\n",
    "        draw.line((snake[i][1], snake[i][0], snake[i + 1][1], snake[i + 1][0]), fill=(255, 0, 0), width=2)\n",
    "    draw.line((snake[-1][1], snake[-1][0], snake[0][1], snake[0][0]), fill=(255, 0, 0), width=2)\n",
    "    return output_image\n",
    "\n",
    "def threshold_and_region_growing(input_image, threshold_value=128, tolerance=10):\n",
    "\n",
    "    # Convert to grayscale\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    \n",
    "    # Apply thresholding\n",
    "    _, binary_image = cv2.threshold(image_array, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Perform region growing using flood fill\n",
    "    binary_image = binary_image.astype(np.uint8)\n",
    "    seed_point = (binary_image.shape[0] // 2, binary_image.shape[1] // 2)\n",
    "    filled_image = cv2.floodFill(binary_image, None, seed_point, 255, flags=cv2.FLOODFILL_FIXED_RANGE, loDiff=(tolerance,)*3, upDiff=(tolerance,)*3)[1]\n",
    "    \n",
    "    # Convert back to PIL image\n",
    "    return Image.fromarray(filled_image)\n",
    "\n",
    "def process_image(input_image, method='sobel', **kwargs):\n",
    "    if method == 'sobel':\n",
    "        return sobel_detector(input_image, **kwargs)\n",
    "    elif method == 'canny':\n",
    "        return canny_detector(input_image, **kwargs)\n",
    "    elif method == 'marr_hildreth':\n",
    "        return marr_hildreth_detector(input_image, **kwargs)\n",
    "    elif method == 'hough':\n",
    "        return hough_transform(input_image, **kwargs)\n",
    "    elif method == 'active_contour':\n",
    "        return active_contour_tracing(input_image, **kwargs)\n",
    "    elif method == 'threshold_region':\n",
    "        return threshold_and_region_growing(input_image, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "\n",
    "input_image = Image.open(\"capybara.jpg\")\n",
    "method = 'active_contour'  \n",
    "if method == 'active_contour':\n",
    "    s = np.linspace(0, 2*np.pi, 473)\n",
    "    r = 140 + 95*np.sin(s)\n",
    "    c = 190 + 150*np.cos(s)\n",
    "    init_points = np.array([r, c]).T\n",
    "    output_image = process_image(input_image, method=method, init_points=init_points)\n",
    "elif method == 'hough':\n",
    "    output_image = process_image(input_image, method=method, canny_low_threshold=50, canny_high_threshold=150, hough_threshold=100, max_lines=50)\n",
    "elif method == 'threshold_region':\n",
    "    output_image = process_image(input_image, method=method, threshold_value=110, tolerance=128)\n",
    "elif method == 'sobel':\n",
    "    output_image = process_image(input_image, method=method, ksize=3)\n",
    "elif method == 'canny':\n",
    "    output_image = process_image(input_image, method=method, low_threshold=100, high_threshold=300)\n",
    "elif method == 'marr_hildreth':\n",
    "    output_image = process_image(input_image, method=method, sigma=3.0)\n",
    "else:\n",
    "    output_image = process_image(input_image, method=method)\n",
    "output_image.save(\"output_image.jpg\")\n",
    "output_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e590ec",
   "metadata": {},
   "source": [
    "## Evaluating\n",
    "For evaluating the edge detection and segmentation algorithms provided in the code, the Berkeley Segmentation Dataset and Benchmark (BSDS500) is a suitable choice. This dataset includes a variety of natural images along with human-annotated ground truth segmentations and boundary annotations, making it ideal for assessing the performance of different image processing algorithms.\n",
    "\n",
    "## Why BSDS300?\n",
    "Variety of Images: It includes a diverse set of natural images.\n",
    "Human-Annotated Ground Truth: Provides multiple ground truth segmentations for each image, allowing for comprehensive evaluation.\n",
    "Standard Benchmark: Widely used in the research community, ensuring that your results can be compared with existing literature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30501a",
   "metadata": {},
   "source": [
    "## Evaluation: By using BSDS300 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0f4b7",
   "metadata": {},
   "source": [
    "Outputs: Precision, recall, F1 score, Processing Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775bcd5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage.filters import gaussian\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sobel_detector(input_image, ksize=3):\n",
    "    gray_image = input_image.convert('L')\n",
    "    image_array = np.array(gray_image)\n",
    "    sobel_x = cv2.Sobel(image_array, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    sobel_y = cv2.Sobel(image_array, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    magnitude = np.hypot(sobel_x, sobel_y)\n",
    "    magnitude = (magnitude / magnitude.max()) * 255\n",
    "    magnitude = magnitude.astype(np.uint8)\n",
    "    return Image.fromarray(magnitude)\n",
    "\n",
    "def canny_detector(input_image, low_threshold=50, high_threshold=150):\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    edges = cv2.Canny(image_array, low_threshold, high_threshold)\n",
    "    return Image.fromarray(edges)\n",
    "\n",
    "def marr_hildreth_detector(input_image, sigma=1.0):\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    blurred_image = cv2.GaussianBlur(image_array, (0, 0), sigma)\n",
    "    laplacian = cv2.Laplacian(blurred_image, cv2.CV_64F)\n",
    "    zero_crossings = np.zeros_like(laplacian)\n",
    "    for i in range(1, laplacian.shape[0] - 1):\n",
    "        for j in range(1, laplacian.shape[1] - 1):\n",
    "            if laplacian[i, j] == 0:\n",
    "                if (laplacian[i+1, j] < 0 and laplacian[i-1, j] > 0) or (laplacian[i+1, j] > 0 and laplacian[i-1, j] < 0) or \\\n",
    "                   (laplacian[i, j+1] < 0 and laplacian[i, j-1] > 0) or (laplacian[i, j+1] > 0 and laplacian[i, j-1] < 0):\n",
    "                    zero_crossings[i, j] = 255\n",
    "            elif laplacian[i, j] < 0:\n",
    "                if (laplacian[i+1, j] > 0 or laplacian[i-1, j] > 0 or laplacian[i, j+1] > 0 or laplacian[i, j-1] > 0):\n",
    "                    zero_crossings[i, j] = 255\n",
    "            elif laplacian[i, j] > 0:\n",
    "                if (laplacian[i+1, j] < 0 or laplacian[i-1, j] < 0 or laplacian[i, j+1] < 0 or laplacian[i, j-1] < 0):\n",
    "                    zero_crossings[i, j] = 255\n",
    "    zero_crossings = zero_crossings.astype(np.uint8)\n",
    "    return Image.fromarray(zero_crossings)\n",
    "\n",
    "def hough_transform(input_image, canny_low_threshold=50, canny_high_threshold=150, hough_threshold=100, max_lines=10):\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    edges = cv2.Canny(image_array, canny_low_threshold, canny_high_threshold)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, hough_threshold)\n",
    "    output_image = input_image.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(output_image)\n",
    "    if lines is not None:\n",
    "        for i, line in enumerate(lines[:max_lines]):\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            draw.line((x1, y1, x2, y2), fill=(255, 0, 0), width=2)\n",
    "    return output_image\n",
    "\n",
    "def active_contour_tracing(input_image, alpha=0.015, beta=10, gamma=0.001, sigma=1.0):\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    image_array = gaussian(image_array, sigma=sigma)\n",
    "    \n",
    "    s = np.linspace(0, 2 * np.pi, 400)\n",
    "    r = 100 + 50 * np.sin(s)\n",
    "    c = 100 + 50 * np.cos(s)\n",
    "    init_points = np.array([r, c]).T\n",
    "    \n",
    "    snake = active_contour(image_array, init_points, alpha=alpha, beta=beta, gamma=gamma)\n",
    "    output_image = input_image.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(output_image)\n",
    "    for i in range(len(snake) - 1):\n",
    "        draw.line((snake[i][1], snake[i][0], snake[i + 1][1], snake[i + 1][0]), fill=(255, 0, 0), width=2)\n",
    "    draw.line((snake[-1][1], snake[-1][0], snake[0][1], snake[0][0]), fill=(255, 0, 0), width=2)\n",
    "    return output_image\n",
    "\n",
    "def threshold_and_region_growing(input_image, threshold_value=128, tolerance=10):\n",
    "    image_array = np.array(input_image.convert('L'))\n",
    "    _, binary_image = cv2.threshold(image_array, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    binary_image = binary_image.astype(np.uint8)\n",
    "    seed_point = (binary_image.shape[0] // 2, binary_image.shape[1] // 2)\n",
    "    filled_image = cv2.floodFill(binary_image, None, seed_point, 255, flags=cv2.FLOODFILL_FIXED_RANGE, loDiff=(tolerance,)*3, upDiff=(tolerance,)*3)[1]\n",
    "    return Image.fromarray(filled_image)\n",
    "\n",
    "def process_image(input_image, method='sobel', **kwargs):\n",
    "    if method == 'sobel':\n",
    "        return sobel_detector(input_image, **kwargs)\n",
    "    elif method == 'canny':\n",
    "        return canny_detector(input_image, **kwargs)\n",
    "    elif method == 'marr_hildreth':\n",
    "        return marr_hildreth_detector(input_image, **kwargs)\n",
    "    elif method == 'hough':\n",
    "        return hough_transform(input_image, **kwargs)\n",
    "    elif method == 'active_contour':\n",
    "        return active_contour_tracing(input_image, **kwargs)\n",
    "    elif method == 'threshold_region':\n",
    "        return threshold_and_region_growing(input_image, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "def evaluate_algorithm(gt_edges, pred_edges):\n",
    "    precision = np.sum(pred_edges & gt_edges) / np.sum(pred_edges)\n",
    "    recall = np.sum(pred_edges & gt_edges) / np.sum(gt_edges)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def run_experiments_and_evaluate(image_paths, methods_params):\n",
    "    results = []\n",
    "    for image_path in image_paths:\n",
    "        input_image = Image.open(image_path)\n",
    "        gt_edges = np.array(input_image.convert('L')) > 128 \n",
    "\n",
    "        for method, params_list in methods_params.items():\n",
    "            for params in params_list:\n",
    "                start_time = time.time()\n",
    "                pred_image = process_image(input_image, method=method, **params)\n",
    "                pred_edges = np.array(pred_image.convert('L')) > 128\n",
    "                end_time = time.time()\n",
    "                \n",
    "                precision, recall, f1_score = evaluate_algorithm(gt_edges, pred_edges)\n",
    "                processing_time = end_time - start_time\n",
    "                results.append((image_path, method, params, precision, recall, f1_score, processing_time))\n",
    "                print(f\"Evaluated {method} with params {params} on {image_path}: Precision={precision}, Recall={recall}, F1={f1_score}, Time={processing_time:.2f}s\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_bsds300_images(dataset_path):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    return image_paths\n",
    "\n",
    "def main():\n",
    "    dataset_path = 'BSDS300/images'  \n",
    "    image_paths = load_bsds300_images(dataset_path)\n",
    "    methods_params = {\n",
    "        'sobel': [{'ksize': k} for k in [3, 5, 7]],\n",
    "        'canny': [{'low_threshold': lt, 'high_threshold': ht} for lt in [50, 100] for ht in [150, 200]],\n",
    "        'marr_hildreth': [{'sigma': s} for s in [0.5, 1.0, 2.0]],\n",
    "        'hough': [{'canny_low_threshold': clt, 'canny_high_threshold': cht, 'hough_threshold': ht, 'max_lines': ml} \n",
    "                  for clt in [50, 100] for cht in [150, 200] for ht in [50, 100] for ml in [10, 20]],\n",
    "        'active_contour': [{'alpha': a, 'beta': b, 'gamma': g, 'sigma': s} \n",
    "                           for a in [0.015, 0.02] for b in [10, 20] for g in [0.001, 0.01] for s in [1.0, 2.0]],\n",
    "        'threshold_region': [{'threshold_value': tv, 'tolerance': t} for tv in [128, 150] for t in [10, 20]]\n",
    "    }\n",
    "    results = run_experiments_and_evaluate(image_paths, methods_params)\n",
    "    \n",
    "    results_file = 'experiment_results.txt'\n",
    "    with open(results_file, 'w') as f:\n",
    "        for result in results:\n",
    "            f.write(f\"{result}\\n\")\n",
    "    print(f\"Results saved to {results_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01400b",
   "metadata": {},
   "source": [
    "## Results analyzation and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23233a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_results(file_path):\n",
    "    results = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            results.append(ast.literal_eval(line.strip()))\n",
    "    return results\n",
    "\n",
    "def analyze_results(results):\n",
    "    df = pd.DataFrame(results, columns=['Image', 'Algorithm', 'Parameters', 'Precision', 'Recall', 'F1 Score', 'Processing Time'])\n",
    "    \n",
    "    mean_performance = df.groupby('Algorithm')[['Precision', 'Recall', 'F1 Score', 'Processing Time']].mean().reset_index()\n",
    "    \n",
    "    print(\"Mean Performance:\")\n",
    "    print(mean_performance)\n",
    "    \n",
    "    return df, mean_performance\n",
    "\n",
    "def find_best_parameters(df):\n",
    "    best_params = df.loc[df.groupby('Algorithm')['F1 Score'].idxmax()]\n",
    "    print(\"\\nBest Parameters for Each Algorithm:\")\n",
    "    print(best_params)\n",
    "    return best_params\n",
    "\n",
    "def plot_performance(mean_performance):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax1.set_title('Performance Comparison of Different Algorithms')\n",
    "    ax1.set_xlabel('Algorithm')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.bar(mean_performance['Algorithm'], mean_performance['Precision'], color='b', alpha=0.6, label='Precision')\n",
    "    ax1.bar(mean_performance['Algorithm'], mean_performance['Recall'], color='g', alpha=0.6, label='Recall', bottom=mean_performance['Precision'])\n",
    "    ax1.bar(mean_performance['Algorithm'], mean_performance['F1 Score'], color='r', alpha=0.6, label='F1 Score', bottom=mean_performance['Precision'] + mean_performance['Recall'])\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Processing Time (s)')\n",
    "    ax2.plot(mean_performance['Algorithm'], mean_performance['Processing Time'], color='k', marker='o', linestyle='dashed', label='Processing Time')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    results_file = 'experiment_results.txt'\n",
    "    results = read_results(results_file)\n",
    "    \n",
    "    df, mean_performance = analyze_results(results)\n",
    "    best_params = find_best_parameters(df)\n",
    "    \n",
    "    plot_performance(mean_performance)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
