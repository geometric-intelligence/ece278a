{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Enable few-shot learning for biomedical image segmentation \n",
    "## Stand upon previous knowledge & explainable frameworks\n",
    "\n",
    "Peicheng Wu, Yequan Zhao, Yubin Deng, Zhixiong Chen, Liyan Tan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Semantic Segmentation (SS): Classifies each pixel in an image into a predefined class.\n",
    "\n",
    "Instance Segmentation (IS): Identifies and delineates each object of interest in an image (differentiates between instances of the same class)\n",
    "\n",
    "Application in biomedical study:\n",
    "* Segmentation of cell bodies, membranes and nuclei from microscopy images\n",
    "\n",
    "Deep Learning based models have achieved great success in biomedical segmentation.\n",
    "\n",
    "<center><img src=\"figs/instance_seg.png\" width=500px alt=\"default\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problems of Deep Learning based Segmentation:\n",
    "\n",
    "* (Big) Data-driven\n",
    "    - Need large amount (e.g., > 10000) expert annotated training data\n",
    "    - Not capable of few-shot learning (i.e., with small (<100) trainig data)\n",
    "* Lack explainability\n",
    "    - Black-box nature of deep learning based methods\n",
    "    - Trustworthy? \n",
    "* Huge computational overhead (high-end GPUs)\n",
    "    - Sustainability?\n",
    "    - Data privacy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem Formulation:\n",
    "\n",
    "Reasons behind: previous biomedical segmentation frameworks are total data-driven, without building on previous (human) knowledge or experience\n",
    "\n",
    "Target: involve previous human knowledge and experience in bimedical image segmentation framework to\n",
    "\n",
    "* Enable few-shot learning\n",
    "* Enhance explainability / transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Presentation Distribution:\n",
    "\n",
    "* Background & Problem formulation: Yequan Zhao\n",
    "\n",
    "* Cellpose[1]: Deep learning based method capable of small dataset adaptation\n",
    "    - High-level ideas & framework explained: Yubin Deng\n",
    "    - Experiment results: Zhixiong Chen\n",
    "\n",
    "* Kartezio[2]: Fully transparent and easily interpretable segmentation pipeline for few-shot learning\n",
    "    - High-level ideas & framework explained: Liyan Tan\n",
    "    - Experiment results: Peicheng Wu\n",
    "\n",
    "[1]: Pachitariu, M. & Stringer, C. (2022). Cellpose 2.0: how to train your own model. Nature methods, 1-8.\n",
    "\n",
    "[2]: Cortacero, Kévin, et al. \"Evolutionary design of explainable algorithms for biomedical image segmentation.\" Nature communications 14.1 (2023): 7112."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cellpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation\n",
    "\n",
    "We expect to save human labor via fully-automated methods (e.g., data-driven deep learning), but...\n",
    "\n",
    "- need huge amount of data → huge amount of expert annotated training data\n",
    "- Do not generalize well to new data source → repeated annotation and training\n",
    "\n",
    "Problem: Previous deep learning based methods lack generalizability / transferability, due to \n",
    "- Limited model capacity\n",
    "- Only trained on specialized datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Method:\n",
    "\n",
    "  1. Developed a new model with better expressive ability\n",
    "\n",
    "  <center><img src=\"figs/CellposeArch.jpg\" width=\"500\" height=\"500\" alt=\"Description of image\"><center>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Method:\n",
    "\n",
    "2. New training dataset:  \n",
    "  - Generalist dataset: to generalize the model more widely and more robustly.\n",
    "    - Exisitng specialized datasets for cell segmentation\n",
    "    - Internet searches for keywords such as ‘cytoplasm’, ‘cellular microscopy’, ‘fluorescent cells’, \n",
    "    - Other types of microscopy images\n",
    "    - Nonmicroscopy images: fruits, rocks, jellyfish\n",
    "\n",
    "  * Specialist dataset: to benchmark expressive power\n",
    "    * 100 images from Cell Image Library\n",
    "    * large and visually uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Further adapt to few-shot learning:\n",
    "\n",
    "<center><img src=\"figs/humanloop.jpg\" width=1000px alt=\"default\"/></center>\n",
    "\n",
    "With Cellpose generalist pretrained model, we could quick adapt to new data with fewer training data:\n",
    "\n",
    "- training from scratch: 200,000 user-annotated regions of interest (ROI)\n",
    "- fine-tune from Cellpose pretrained model: only 500–1,000 ROI\n",
    "- human-in-the-loop pipeline: reduced the required user annotation to 100–200 ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kartezio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation:\n",
    "\n",
    "Cellpose enables few-shot learning, but \n",
    "* only for cell segmentation tasks\n",
    "* cannot guarantee explainability / transparency due to the \"black box\" nature of deep learning models\n",
    "\n",
    "Need for Explainability:\n",
    "* A growing demand for algorithms that are not only effective but also transparent and interpretable. \n",
    "* Decisions must be justifiable and comprehensible in medical and biological settings.\n",
    "\n",
    "Kartezio is a fully explainable framwork, with \n",
    "* comparable performance to Cellpose in small dataset (100)\n",
    "* better performance in tiny datasets (10~20)\n",
    "* few-shot learning for general segmentation tasks including cell segmentation, tumor segmentation， etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Highlights of core methods:\n",
    "\n",
    "Explainability and Transparency:\n",
    "  * Kartezio is designed to create fully transparent and interpretable image processing pipelines.\n",
    "  * Kartezio's pipelines can be easily understood and inspected by humans.\n",
    "\n",
    "Few-Shot Learning:\n",
    "  * The ability to perform effectively with much smaller training datasets.\n",
    "\n",
    "Modularity and Flexibility:\n",
    "  * The modular nature is based on Cartesian Genetic Programming (CGP).\n",
    "  * Adaptively assemble and parameterize CV functions to create custom pipelines.\n",
    "  * Integration of Expert Knowledge: decades of human expertise into its pipeline generation process.\n",
    "\n",
    "Practical Utility & Complement to DL:\n",
    "  * Effective across a variety of imaging types and scenarios in biomedicine.\n",
    "  * A complementary tool for deep learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Framework\n",
    "\n",
    "<center><img src=\"figs/kartezio_framework.png\" width=1000px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model examle\n",
    "\n",
    "<center><img src=\"figs/kartezio_example.png\" width=1000px alt=\"default\"/></center>\n",
    "\n",
    "Hence, we can see Kartezio as a method to find a better way to preprocess specific images (cancer or other medical images).  It is driven by the CGA which can automatically search which functions combined together is better.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
